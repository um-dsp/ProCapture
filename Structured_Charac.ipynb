{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from library.Accessor import Accessor\n",
    "from library.attributionUtils import get_attributes,adversarial_detection_set\n",
    "from library.attributions import multiply_attributed_with_input,number_of_active_nodes\n",
    "from library.train import binary_acc\n",
    "\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'mnist' # can be mnist, cifar10, cuckoo, ember\n",
    "model_name = 'mnist_1' # can be 'cifar10_1','cuckoo_1','Ember_2','mnist_1','mnist_2','mnist_3'\n",
    "attack= 'FGSM' # can be 'FGSM','CW','PGD',\"CKO\",'EMBER'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Benign testing activations...\n",
      "Loaded all activations for ./Benign/mnist/mnist_1/\n",
      "Loading Adversarial testing activations...\n",
      "Loaded all activations for ./Adversarial/mnist/FGSM/mnist_1/\n"
     ]
    }
   ],
   "source": [
    "test_benign_accessor = Accessor('./Benign/'+dataset+'/' +model_name +'/')\n",
    "test_adv_accessor= Accessor('./Adversarial/'+dataset+'/'+attack +'/' +model_name +'/' )\n",
    "#ground_truth_accessor = Accessor('./Ground_truth/mnist/mnist_1')\n",
    "\n",
    "print('Loading Benign testing activations...')\n",
    "test_benign_act = test_benign_accessor.get_all()\n",
    "print('Loading Adversarial testing activations...')\n",
    "test_adv_act = test_adv_accessor.get_all()\n",
    "#gt_sample_act = ground_truth_accessor.get_all()\n",
    "\n",
    "\n",
    "\n",
    "# Transforms the activations to the folowing data set : x[activationA,activaitonB,...]  y= [1, 0 ,1...]\n",
    "X_adv,Y_adv = adversarial_detection_set(test_adv_act,label = torch.tensor(1.0))\n",
    "X_ben,Y_ben = adversarial_detection_set(test_benign_act,label = torch.tensor(0.0))\n",
    "#X_gt ,Y_gt =adversarial_detection_set(gt_sample_act,label = torch.tensor(0),expected_nb_nodes=expected_nb_nodes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of testing adv activations: torch.Size([9834, 1204])\n",
      "Shape of testing ben activations: torch.Size([10000, 1204])\n",
      "Model accuracy:  100.0\n"
     ]
    }
   ],
   "source": [
    "## Testing model on test data\n",
    "# We sample equal number of adversarial and benign data ...\n",
    "shape_min = np.min([X_adv.shape[0],X_ben.shape[0]])\n",
    "X_test = torch.cat((X_adv[:shape_min],X_ben[:shape_min]))# + X_gt\n",
    "Y_test= torch.cat((Y_adv[:shape_min], Y_ben[:shape_min]))# + Y_gt\n",
    "\n",
    "print('Shape of testing adv activations:',X_adv.shape)\n",
    "print('Shape of testing ben activations:',X_ben.shape)\n",
    "\n",
    "model = torch.load('./models/mnist_1_graph.pt')\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model=model.cuda()\n",
    "\n",
    "X_test=torch.Tensor(X_test)\n",
    "Y_test=torch.Tensor(Y_test)\n",
    "    \n",
    "model.eval()\n",
    "y_pred = model(X_test)\n",
    "\n",
    "acc = binary_acc(y_pred, Y_test.unsqueeze(1))#(y_pred.round() == Y_test).float().mean()\n",
    "acc = float(acc)\n",
    "print('Model accuracy: ',float(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([9834, 1204])\n",
      "torch.Size([10000, 1204])\n",
      "Average Attributes of Adversarial samples:1.4938300500204521e-07 \n",
      " Average Attributes of Benign samples: -0.000830439291968719\n"
     ]
    }
   ],
   "source": [
    "## Performing adv and benign data feature attribution on the model\n",
    "'''Attribution is performed with respect to the label 0 (benign)\n",
    "If the attribute is postive: the node is directed to the label 0, \n",
    "otherwise it is directed to the label 1'''\n",
    "\n",
    "adv_mul, adv_attr =multiply_attributed_with_input(X_adv,Y_adv,model)\n",
    "ben_mul, ben_attr =multiply_attributed_with_input(X_ben,Y_ben,model)\n",
    "#gt_attr =multiply_attributed_with_input(X_gt,Y_gt,model)\n",
    "\n",
    "avg_adv = [np.average(i) for i in adv_attr]\n",
    "avg_ben = [np.average(i) for i in ben_attr]\n",
    "#gt_attr = [np.average(i) for i in gt_attr]\n",
    "\n",
    "print(f'Average Attributes of Adversarial samples:{np.average(avg_adv)} \\n Average Attributes of Benign samples: {np.average(avg_ben)}')# Gt : {np.average(gt_attr)} ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from library.attributionUtils import get_nodes_data\n",
    "\n",
    "# nodes characteristics of adv data\n",
    "adv_weights,adv_atts, adv_avg_weights, adv_avg_atts = get_nodes_data(X_adv, adv_attr)\n",
    "\n",
    "# nodes characteristics of Benign data\n",
    "ben_weights,ben_atts, ben_avg_weights, ben_avg_atts = get_nodes_data(X_ben, ben_attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x_axis = range(X_adv.shape[1]) # Nodes\n",
    "\n",
    "def bar_plot(x_axis, y_ben, y_adv, x_label, y_label, title, xticks=None):\n",
    "    \n",
    "    # set width of bar\n",
    "    barWidth = 0.25\n",
    "    fig = plt.subplots(figsize =(12, 8))\n",
    "    \n",
    "    # set x positions\n",
    "    x_ben = [x - barWidth/2 for x in x_axis]\n",
    "    x_adv = [x + barWidth/2 for x in x_axis]\n",
    "    \n",
    "    plt.bar(x_ben, y_ben,color ='green', width = barWidth,\n",
    "        edgecolor ='green', label ='Benign')\n",
    "    plt.bar(x_adv, y_adv,color ='r', width = barWidth,\n",
    "        edgecolor ='red', label ='Adv')\n",
    "    plt.title(title)\n",
    "    plt.xlabel(x_label)\n",
    "    plt.ylabel(y_label)\n",
    "    if xticks != None:\n",
    "        plt.xticks(x_axis,labels=xticks,rotation='vertical')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot avg weights of all nodes\n",
    "bar_plot(x_axis,ben_avg_weights,adv_avg_weights, 'Nodes', 'Avg Activation Weights', 'Avg Activation weights of each Node across all benign/Adversarial samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nodes have bigger weights when samples are benign.\n",
    "\n",
    "**Hypothesis: When nodes activations are very low. This could be a sign that the model is under attack and its output could be wrong.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot avg Attributes of all nodes\n",
    "bar_plot(x_axis,ben_avg_atts,adv_avg_atts, 'Nodes', 'Avg Attributes', 'Avg Attributes of each Node across all benign/Adversarial samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot avg Attributes of all nodes\n",
    "bar_plot(x_axis,len(ben_avg_atts)*[0],adv_avg_atts, 'Nodes', 'Avg Attributes', 'Avg Attributes of each Node across all benign/Adversarial samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a clearer look on the most relevant Nodes, we filter those that are irrelevant to the prediction. More precisely, we discard nodes with an average attribute value close to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select a thresholds\n",
    "threshold_ben = 0.01\n",
    "threshold_Adv = 0.00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ben_node_filter = [np.abs(x) > threshold_ben for x in ben_avg_atts]\n",
    "ben_nodes = [x_axis[i] for i in range(len(x_axis)) if ben_node_filter[i]]\n",
    "print('Nodes that are relevant to the benign samples are:\\n',ben_nodes)\n",
    "print('\\n len = ',len(ben_nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_node_filter = [np.abs(x) > threshold_Adv for x in adv_avg_atts]\n",
    "adv_nodes = [x_axis[i] for i in range(len(x_axis)) if adv_node_filter[i]]\n",
    "print('Nodes that are relevant to the Adversarial samples are:\\n',adv_nodes)\n",
    "print('\\n len = ',len(adv_nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge all relavant nodes\n",
    "nodes = adv_nodes + ben_nodes\n",
    "nodes = list(set(nodes))\n",
    "nodes.sort()\n",
    "print('studied nodes are : \\n',nodes)\n",
    "print('\\n len = ',len(nodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ben_avg_atts_filtered = [ben_avg_atts[i] for i in range(len(x_axis)) if i in nodes]\n",
    "adv_avg_atts_filtered = [adv_avg_atts[i] for i in range(len(x_axis)) if i in nodes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot avg Attributes of all nodes\n",
    "bar_plot(range(len(nodes)),ben_avg_atts_filtered,adv_avg_atts_filtered, 'Nodes', 'Avg Attributes', 'Avg Attributes of each Node across all benign/Adversarial samples', xticks=nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## rescaling Adv attributions to plot both types of data together\n",
    "bar_plot(range(len(nodes)),ben_avg_atts_filtered,[x*1000 for x in adv_avg_atts_filtered], 'Nodes', 'Avg Attributes', 'Avg Attributes of each Node across all benign/Adversarial samples', xticks=nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ben_atts_filtered = [ben_atts[i] for i in range(len(x_axis)) if i in nodes]\n",
    "adv_atts_filtered = [adv_atts[i] for i in range(len(x_axis)) if i in nodes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boxplot(x_axis, y_ben, y_adv, x_label, y_label, title, xticks=None):\n",
    "     \n",
    "    # set width of box\n",
    "    boxWidth = 0.25\n",
    "    fig1, ax1 = plt.subplots()\n",
    "    \n",
    "    # set x positions\n",
    "    x_ben = [x - boxWidth/2 for x in x_axis]\n",
    "    x_adv = [x + boxWidth/2 for x in x_axis]\n",
    "    \n",
    "    \n",
    "    plt.title(title)\n",
    "    plt.xlabel(x_label)\n",
    "    #plt.ylabel(y_label)\n",
    "    #if xticks != None:\n",
    "    #    plt.xticks(x_axis,labels=xticks,rotation='vertical')\n",
    "    \n",
    "\n",
    "    # Creating plot\n",
    "    bx1 = ax1.boxplot(y_ben,notch=True,whis=2,positions=x_ben,widths=boxWidth,patch_artist=True,showfliers=False)\n",
    "    ax1.set_xticks(x_axis,labels=xticks,rotation=90)\n",
    "    ax1.set_ylabel(y_label+' Benign')\n",
    "    plt.setp(bx1[\"boxes\"], facecolor='green',label='Benign')\n",
    "    \n",
    "    ax2 = ax1.twinx()\n",
    "    \n",
    "    # Creating plot\n",
    "    bx2 = ax2.boxplot(y_adv,notch=True,whis=2,positions=x_adv,widths=boxWidth,patch_artist=True,showfliers=False)\n",
    "    ax2.set_xticks(x_axis,labels=xticks,rotation=90)\n",
    "    ax2.set_ylabel(y_label+' Adversarial')\n",
    "    plt.setp(bx2[\"boxes\"], facecolor='red',label='Adversarial')\n",
    "    \n",
    "    by_label={0: 'Adversarial',\n",
    "             1: 'Benign'}\n",
    "    \n",
    "    # show plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot(range(len(nodes)),ben_atts_filtered,[x for x in adv_atts_filtered], 'Nodes', 'Attributes', 'Attributes of each Node across all benign/Adversarial samples', xticks=nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ben_weights_filtered = [ben_weights[i] for i in range(len(x_axis)) if i in nodes]\n",
    "adv_weights_filtered = [adv_weights[i] for i in range(len(x_axis)) if i in nodes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxplot(range(len(nodes)),ben_weights_filtered,[x for x in adv_weights_filtered], 'Nodes', 'Activation Weights', 'Activation Weights of each Node across all benign/Adversarial samples', xticks=nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
