{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from library.Accessor import Accessor\n",
    "from library.metrics import expD, expE,expF,expG,expH,expI, avg_act_diff, compare\n",
    "from library.utils import plotAcrossPredictions, plotAcrossNodes, plotDiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiate and Accessor class with a folder containing activations csv/txt\n",
    "\n",
    "### Uncomment to use MNIST\n",
    "\n",
    "data='mnist'\n",
    "FGSM_sample = Accessor('./adversarial/mnist/FGSM/mnist_1')\n",
    "PGD_sample = Accessor('./adversarial/mnist/PGD/mnist_1')\n",
    "begning_sample = Accessor('./Benign/mnist/mnist_1')\n",
    "ground_truth = Accessor('./Ground_truth/mnist/mnist_1')\n",
    "\n",
    "'''\n",
    "### Uncomment to use CIFAR10\n",
    "data='cifar10'\n",
    "FGSM_sample = Accessor('./adversarial/cifar10/FGSM/cifar10_1')\n",
    "PGD_sample = Accessor('./adversarial/cifar10/PGD/cifar10_1')\n",
    "begning_sample = Accessor('./Benign/cifar10/cifar10_1')\n",
    "ground_truth = Accessor('./Ground_truth/cifar10/cifar10_1')\n",
    "\n",
    "\n",
    "### Uncomment to use Cuckoo-Traces\n",
    "data='cuckoo'\n",
    "FGSM_sample = Accessor('./adversarial//FGSM/')\n",
    "PGD_sample = Accessor('./adversarial//PGD/')\n",
    "begning_sample = Accessor('./begnign//')\n",
    "ground_truth = Accessor('./Ground_truth//')\n",
    "\n",
    "### Uncomment to use Ember\n",
    "data='Ember'\n",
    "FGSM_sample = Accessor('./adversarial//FGSM/')\n",
    "PGD_sample = Accessor('./adversarial//PGD/')\n",
    "begning_sample = Accessor('./begnign//')\n",
    "ground_truth = Accessor('./Ground_truth//')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use this to load all activations\n",
    "'''\n",
    "### Loading MNIST activation\n",
    "M_begning_sample_act = M_begning_sample.get_all(limit=5000)   \n",
    "M_FGSM_sample_act = M_FGSM_sample.get_all(limit=5000)\n",
    "M_PGD_sample_act = M_PGD_sample.get_all(limit=5000)\n",
    "M_ground_truth_act = M_ground_truth.get_all(limit=5000)\n",
    "\n",
    "\n",
    "### Loading CIFAR10 activations\n",
    "C_begning_sample_act = C_begning_sample.get_all(limit=5000)   \n",
    "C_FGSM_sample_act = C_FGSM_sample.get_all(limit=5000)\n",
    "C_PGD_sample_act = C_PGD_sample.get_all(limit=5000)\n",
    "C_ground_truth_act = C_ground_truth.get_all(limit=5000)\n",
    "\n",
    "### Loading Cuckoo-Traces activations\n",
    "Cu_begning_sample_act = Cu_begning_sample.get_all(limit=5000)   \n",
    "Cu_FGSM_sample_act = Cu_FGSM_sample.get_all(limit=5000)\n",
    "Cu_PGD_sample_act = Cu_PGD_sample.get_all(limit=5000)\n",
    "Cu_ground_truth_act = Cu_ground_truth.get_all(limit=5000)\n",
    "\n",
    "### Loading Ember activations\n",
    "Cu_begning_sample_act = Cu_begning_sample.get_all(limit=5000)   \n",
    "Cu_FGSM_sample_act = Cu_FGSM_sample.get_all(limit=5000)\n",
    "Cu_PGD_sample_act = Cu_PGD_sample.get_all(limit=5000)\n",
    "Cu_ground_truth_act = Cu_ground_truth.get_all(limit=5000)\n",
    "\n",
    "\n",
    "## Computing the similarity rate of the activation graph of each type of data\n",
    "print(compare(M_begning_sample_act, M_FGSM_sample_act))\n",
    "print(compare(M_begning_sample_act, M_PGD_sample_act))\n",
    "print(compare(M_FGSM_sample_act, M_PGD_sample_act))\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We use the following notations for each graph-based metric adopted for empirical characterization\n",
    " \n",
    " avg_act_diff: Compute the difference between model activations of different types of data (e.g. FGSM, Benign, etc) <br>\n",
    " ExpD : Average number of Active Nodes <br>\n",
    " ExpE : Average Activations Weight<br>\n",
    " ExpF : Always Active Nodes <br>\n",
    " ExpG : Frequency Distances<br>\n",
    " ExpH : Dispersation Index<br>\n",
    " ExpI : Entropy Index<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt = {'D':[],'E':[],'H':[],'I':[], 'G':[] , 'F':[]}\n",
    "ben = {'D':[],'E':[],'H':[],'I':[], 'G':[], 'F':[]}\n",
    "FGSM={'D':[],'E':[],'H':[],'I':[], 'G':[], 'F':[]}\n",
    "PGD={'D':[],'E':[],'H':[],'I':[], 'G':[], 'F':[]}\n",
    "\n",
    "FGSM_diff=[]\n",
    "PGD_diff=[]\n",
    "adv_diff=[]\n",
    "\n",
    "PRED_RANGE = 10\n",
    "nb_samples=1000\n",
    "\n",
    "for i in range(PRED_RANGE):\n",
    "    \n",
    "    ## Loading activations by prediction\n",
    "    begning_sample_act = begning_sample.get_label_by_prediction(target_prediction=i,limit=nb_samples)   \n",
    "    FGSM_sample_act = FGSM_sample.get_label_by_prediction(target_prediction=i,limit=nb_samples)\n",
    "    PGD_sample_act = PGD_sample.get_label_by_prediction(target_prediction=i,limit=nb_samples)\n",
    "    ground_truth_act = ground_truth.get_label_by_prediction(target_prediction=i,limit=nb_samples)\n",
    "    \n",
    "    print('label = ',i,'\\n')\n",
    "    print(\"the average similarity between ben and FGSM is {}% \".format(compare(begning_sample_act, FGSM_sample_act,nb_sample=nb_samples)))\n",
    "    print(\"the average similarity between ben and PGD is {}% \".format(compare(begning_sample_act, PGD_sample_act,nb_sample=nb_samples)))\n",
    "    print(\"the average similarity between PGD and FGSM is {}% \".format(compare(FGSM_sample_act, PGD_sample_act,nb_sample=nb_samples)))\n",
    "    \n",
    "    FGSM_diff.append(avg_act_diff(begning_sample_act,FGSM_sample_act,nb_sample=nb_samples))\n",
    "    PGD_diff.append(avg_act_diff(begning_sample_act,PGD_sample_act,nb_sample=nb_samples))\n",
    "    adv_diff.append(avg_act_diff(FGSM_sample_act,PGD_sample_act,nb_sample=nb_samples))\n",
    "    plotDiff(FGSM_diff[i],PGD_diff[i],adv_diff[i],Node_range=len(FGSM_diff[i]),data=data,label=i)\n",
    "    \n",
    "    gt['D'].append(expD(ground_truth_act))\n",
    "    ben['D'].append(expD(begning_sample_act))\n",
    "    FGSM['D'].append(expD(FGSM_sample_act))\n",
    "    PGD['D'].append(expD(PGD_sample_act))\n",
    "    \n",
    "    gt['E'].append(expE(ground_truth_act))\n",
    "    ben['E'].append(expE(begning_sample_act))\n",
    "    FGSM['E'].append(expE(FGSM_sample_act))\n",
    "    PGD['E'].append(expE(PGD_sample_act))\n",
    "    \n",
    "    gt['H'].append(expH(ground_truth_act))\n",
    "    ben['H'].append(expH(begning_sample_act))\n",
    "    FGSM['H'].append(expH(FGSM_sample_act))\n",
    "    PGD['H'].append(expH(PGD_sample_act))\n",
    "    \n",
    "    gt['I'].append(expI(ground_truth_act))\n",
    "    ben['I'].append(expI(begning_sample_act))\n",
    "    FGSM['I'].append(expI(FGSM_sample_act))\n",
    "    PGD['I'].append(expI(PGD_sample_act))\n",
    "    \n",
    "    gt['G'].append(list(expG(ground_truth_act)))\n",
    "    ben['G'].append(list(expG(begning_sample_act)))\n",
    "    FGSM['G'].append(list(expG(FGSM_sample_act)))\n",
    "    PGD['G'].append(list(expG(PGD_sample_act)))\n",
    "    \n",
    "    gt['F'].append(expF(ground_truth_act))\n",
    "    ben['F'].append(expF(begning_sample_act))\n",
    "    FGSM['F'].append(expF(FGSM_sample_act))\n",
    "    PGD['F'].append(expF(PGD_sample_act))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Average Number of Active Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adv=[FGSM['D'], PGD['D']]\n",
    "plotAcrossPredictions(gt['D'],'Average Number of active nodes',ben['D'],adv,PRED_RANGE,data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Always Active Nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Overall labels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_overall = set([item for sublist in gt['F'] for item in sublist])\n",
    "ben_overall = set([item for sublist in ben['F'] for item in sublist])\n",
    "FGSM_overall = set([item for sublist in FGSM['F'] for item in sublist])\n",
    "PGD_overall = set([item for sublist in PGD['F'] for item in sublist])\n",
    "\n",
    "\n",
    "print('GT: ',gt_overall,'\\n')\n",
    "print('Ben: ',ben_overall,'\\n')\n",
    "print('FGSM: ',FGSM_overall,'\\n')\n",
    "print('PGD: ',PGD_overall,'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Intersection overall all labels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Intersection between {} and {} : {}'.format('GT','ben',[value for value in gt_overall if value in ben_overall]),'\\n')\n",
    "print('Intersection between {} and {} : {}'.format('GT','FGSM',[value for value in gt_overall if value in FGSM_overall]),'\\n')\n",
    "print('Intersection between {} and {} : {}'.format('GT','PGD',[value for value in gt_overall if value in PGD_overall]),'\\n')\n",
    "print('Intersection between {} and {} : {}'.format('FGSM','PGD',[value for value in FGSM_overall if value in PGD_overall]),'\\n')\n",
    "print('Intersection between {} and {} : {}'.format('FGSM','ben',[value for value in FGSM_overall if value in ben_overall]),'\\n')\n",
    "print('Intersection between {} and {} : {}'.format('ben','PGD',[value for value in ben_overall if value in PGD_overall]),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Intersection per label**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in range(PRED_RANGE):\n",
    "    print('Prediction = {}:\\n'.format(label))\n",
    "    print('Intersection between {} and {} : {}'.format('GT','ben',[value for value in gt['F'][label] if value in ben['F'][label]]),'\\n')\n",
    "    print('Intersection between {} and {} : {}'.format('GT','FGSM',[value for value in gt['F'][label] if value in FGSM['F'][label]]),'\\n')\n",
    "    print('Intersection between {} and {} : {}'.format('GT','PGD',[value for value in gt['F'][label]if value in PGD['F'][label]]),'\\n')\n",
    "    print('Intersection between {} and {} : {}'.format('FGSM','PGD',[value for value in FGSM['F'][label] if value in PGD['F'][label]]),'\\n')\n",
    "    print('Intersection between {} and {} : {}'.format('FGSM','ben',[value for value in FGSM['F'][label] if value in ben['F'][label]]),'\\n')\n",
    "    print('Intersection between {} and {} : {}'.format('ben','PGD',[value for value in ben['F'][label] if value in PGD['F'][label]]),'\\n')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Number of always active nodes per label**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nb_gt=[]\n",
    "Nb_ben=[]\n",
    "Nb_FGSM=[]\n",
    "Nb_PGD=[]\n",
    "\n",
    "for val in gt['F']:\n",
    "    Nb_gt.append(len(val))\n",
    "    \n",
    "for val in ben['F']:\n",
    "    Nb_ben.append(len(val))\n",
    "    \n",
    "for val in FGSM['F']:\n",
    "    Nb_FGSM.append(len(val))\n",
    "    \n",
    "for val in PGD['F']:\n",
    "    Nb_PGD.append(len(val))\n",
    "    \n",
    "adv=[Nb_FGSM, Nb_PGD]\n",
    "\n",
    "plotAcrossPredictions(Nb_gt,'Number of always active nodes',Nb_ben,adv,PRED_RANGE,data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Node activation frequency\n",
    "### The distance between the activation frequency of GT compared to FGSM, PGD and Benign respectively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "for i in range(PRED_RANGE):\n",
    "    adv=[np.array(FGSM['G'][i]), np.array(PGD['G'][i])]\n",
    "    print('Label= ',i)\n",
    "    plotAcrossNodes(np.array(gt['G'][i]),'Node activation frequency',np.array(ben['G'][i]),adv,Node_range=len(PGD['G'][i]),data=data,label=i)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Average Activations Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adv=[FGSM['E'], PGD['E']]\n",
    "plotAcrossPredictions(gt['E'],'Average Activations Weight',ben['E'],adv,PRED_RANGE,data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Dispersation Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adv=[FGSM['H'], PGD['H']]\n",
    "plotAcrossPredictions(gt['H'],'Average Activations Weight',ben['H'],adv,PRED_RANGE,data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Entropy Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "adv=[FGSM['I'], PGD['I']]\n",
    "plotAcrossPredictions(gt['I'],'Entropy',ben['I'],adv,PRED_RANGE,data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
